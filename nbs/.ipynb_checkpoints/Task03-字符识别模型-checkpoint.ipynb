{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3 字符识别模型     \n",
    "在前面的章节，我们讲解了赛题的背景知识和赛题数据的读取。本章开始构建一个字符识别模型，基于对赛题理解本章将构建一个定长多字符分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 字符识别模型\n",
    "\n",
    "本章将会讲解卷积神经网络（Convolutional Neural Network, CNN）的常见层，并从头搭建一个字符识别模型。     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 学习目标     \n",
    "\n",
    "- 学习CNN基础和原理      \n",
    "- 使用Pytorch框架构建CNN模型，并完成训练      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CNN介绍      \n",
    "\n",
    "卷积神经网络（简称CNN）是一类特殊的人工神经网络，是深度学习中重要的一个分支。CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。      \n",
    "          \n",
    "CNN每一层由众多的卷积核组成，每个卷积核对输入的像素进行卷积操作，得到下一次的输入。随着网络层的增加卷积核会逐渐扩大感受野，并缩减图像的尺寸。        \n",
    "             \n",
    "  ![IMG](../IMG/Task03/卷积.png)    \n",
    "                  \n",
    "CNN是一种层次模型，输入的是原始的像素数据。CNN通过卷积（convolution）、池化（pooling）、非线性激活函数（non-linear activation function）和全连接层（fully connected layer）构成。      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下图所示为LeNet网络结构，是非常经典的字符识别模型。两个卷积层，两个池化层，两个全连接层组成。卷积核都是5×5，stride=1，池化层使用最大池化。    \n",
    "     \n",
    "  \n",
    " ![IMG](../IMG/Task03/Le_CNN.png)       \n",
    "           \n",
    "通过多次卷积和池化，CNN的最后一层将输入的图像像素映射为具体的输出。如在分类任务中会转换为不同类别的概率输出，然后计算真实标签与CNN模型的预测结果的差异，并通过反向传播更新每层的参数，并在更新完成后再次前向传播，如此反复直到训练完成 。\n",
    "         \n",
    "与传统机器学习模型相比，CNN具有一种端到端（End to End）的思路。在CNN训练的过程中是直接从图像像素到最终的输出，并不涉及到具体的特征提取和构建模型的过程，也不需要人工的参与。\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 CNN发展      \n",
    "\n",
    "随着网络结构的发展，研究人员最初发现网络模型结构越深、网络参数越多模型的精度更优。比较典型的是AlexNet、VGG、InceptionV3和ResNet的发展脉络。      \n",
    "![IMG](../IMG/Task03/网络发展.png)\n",
    "      \n",
    "\n",
    " - #### LeNet-5(1998)     \n",
    "\n",
    "   ![IMG](../IMG/Task03/Le_net.png)\n",
    "\n",
    " - #### AlexNet(2012)\n",
    "\n",
    "   ![IMG](../IMG/Task03/Alex-net.png)     \n",
    "\n",
    "- #### VGG-16(2014)   \n",
    "\n",
    "  ![IMG](../IMG/Task03/VGG.png)   \n",
    "\n",
    " - #### Inception-v1 (2014)    \n",
    "\n",
    "   ![IMG](../IMG/Task03/Incep-net.png)      \n",
    "\n",
    " - #### ResNet-50 (2015)    \n",
    "\n",
    "   ![IMG](../IMG/Task03/Resnet50.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pytorch构建CNN模型     \n",
    "\n",
    "在上一章节我们讲解了如何使用Pytorch来读取赛题数据集，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 64, 128]) torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 原始SVHN中类别10为数字0\n",
    "        lbl = np.array(self.img_label[index], dtype=np.long)\n",
    "        lbl = list(lbl)  + (6 - len(lbl)) * [10]\n",
    "        \n",
    "        return img, torch.from_numpy(np.array(lbl[:6]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "train_path = glob.glob('../data/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../data/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            SVHNDataset(train_path, train_label,\n",
    "                    transforms.Compose([\n",
    "                        transforms.Resize((64, 128)),\n",
    "                        transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                        transforms.RandomRotation(5),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])), \n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    num_workers=0, # 读取的线程个数\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for data in train_loader:\n",
    "    if i == 0:\n",
    "        print(data[0].shape, data[1].shape)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节我们使用本章学习到的知识构建一个简单的CNN模型，完成字符识别功能。              \n",
    "在Pytorch中构建CNN模型非常简单，只需要定义好模型的参数和正向传播即可，Pytorch会根据正向传播自动计算反向传播。         \n",
    "        \n",
    "在本章我们会构建一个非常简单的CNN，然后进行训练。这个CNN模型包括两个卷积层，最后并联6个全连接层进行分类。        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 定义模型\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "        # CNN提取特征模块\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),  \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # \n",
    "        self.fc1 = nn.Linear(32*3*7, 11)\n",
    "        self.fc2 = nn.Linear(32*3*7, 11)\n",
    "        self.fc3 = nn.Linear(32*3*7, 11)\n",
    "        self.fc4 = nn.Linear(32*3*7, 11)\n",
    "        self.fc5 = nn.Linear(32*3*7, 11)\n",
    "        self.fc6 = nn.Linear(32*3*7, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5, c6\n",
    "    \n",
    "model = SVHN_Model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是训练代码：       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.005)\n",
    "\n",
    "loss_plot, c0_plot = [], []\n",
    "# 迭代10个Epoch\n",
    "for epoch in range(10):\n",
    "    for data in train_loader:\n",
    "        c0, c1, c2, c3, c4, c5 = model(data[0])\n",
    "        loss = criterion(c0, data[1][:, 0].long()) + \\\n",
    "                criterion(c1, data[1][:, 1].long()) + \\\n",
    "                criterion(c2, data[1][:, 2].long()) + \\\n",
    "                criterion(c3, data[1][:, 3].long()) + \\\n",
    "                criterion(c4, data[1][:, 4].long()) + \\\n",
    "                criterion(c5, data[1][:, 5].long())\n",
    "        loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_plot.append(loss.item())\n",
    "        c0_plot.append((c0.argmax(axis=1) == data[1][:, 0]).sum().item()*1.0 / c0.shape[0])\n",
    "        \n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练完成后我们可以将训练过程中的损失和准确率进行绘制，如下图所示。从图中可以看出模型的损失在迭代过程中逐渐减小，字符预测的准确率逐渐升高。          \n",
    "      \n",
    " ![IMG](../IMG/Task03/loss.png)     \n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然为了追求精度，也可以使用在ImageNet数据集上的预训练模型，具体方法如下：      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model2, self).__init__()\n",
    "                \n",
    "        model_conv = models.resnet18(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 11)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "        self.fc3 = nn.Linear(512, 11)\n",
    "        self.fc4 = nn.Linear(512, 11)\n",
    "        self.fc5 = nn.Linear(512, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        print(feat.shape)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 1, 1])\n",
      "torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model2()\n",
    "c0, c1, c2, c3, c4= model(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 本章小节     \n",
    "\n",
    "在本章中我们介绍了CNN以及CNN的发展，并使用Pytorch构建构建了一个简易的CNN模型来完成字符分类任务。      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1-gpu]",
   "language": "python",
   "name": "conda-env-pytorch1-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
